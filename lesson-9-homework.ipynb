{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388c2ed3-8b9c-4bbe-b358-e420a94b306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#（1）参照BiGram代码，实现TriGram模型的设计，在199801.txt数据集上完成TriGram模型的学习，并提供使用训练好的TriGram模型生成一句话的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968caa94-c37a-478a-ad67-1378f6f0b33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\86184\\Desktop\\文本分析\n"
     ]
    }
   ],
   "source": [
    "#检查并定义工作目录\n",
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('C:/Users/86184/Desktop/文本分析')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db19e1e9-6f01-4949-aef6-0bf36cc533d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import heapq\n",
    "import random\n",
    "\n",
    "import re  # 导入正则表达式模块\n",
    "\n",
    "class BiGram:\n",
    "    def __init__(self, topk=10000):\n",
    "        self.i2w = {}\n",
    "        self.w2i = {}\n",
    "        self.M = None\n",
    "        self.topk = topk\n",
    "        return None\n",
    "    \n",
    "    def sort_dict(self,d):\n",
    "        sorted_d = sorted(d.items(), key = lambda item: item[1], reverse = True)\n",
    "        return sorted_d\n",
    "    \n",
    "    def train(self, trainset):\n",
    "        unkown = '<UKN>'\n",
    "        start = '<S>'\n",
    "        end = '<E>'\n",
    "        self.i2w[0]=unkown\n",
    "        self.i2w[1]=start\n",
    "        self.i2w[2]=end\n",
    "        totalcount = 0   #总词数\n",
    "        wordcount = defaultdict(int)  #词频\n",
    "        wordcount[start] = len(trainset)  #<s>句子开始标记数\n",
    "        wordcount[end] = len(trainset)   #<e>句子结束标记数\n",
    "        print(\"词频统计中...\")\n",
    "        #词频统计\n",
    "        for sentence in trainset:\n",
    "            for word in sentence:\n",
    "                wordcount[word]+=1\n",
    "        \n",
    "        #汇总总词数\n",
    "        for _,v in wordcount.items():\n",
    "            totalcount+=v\n",
    "        \n",
    "        \n",
    "        #选取topk高频词，同时获得 索引 与 词 的mapping \n",
    "        print(\"生成词表...\")\n",
    "        i = 3\n",
    "        for w,_ in self.sort_dict(wordcount):\n",
    "            if i < self.topk+3:\n",
    "                self.i2w[i]=w\n",
    "            i+=1\n",
    "        \n",
    "        #获得 词 与 索引 的mapping \n",
    "        for i,w in self.i2w.items():\n",
    "            self.w2i[w] = i\n",
    "        #print(self.w2i)\n",
    "        \n",
    "        #获得保留词的词频\n",
    "        wordcount_filter = defaultdict(int)\n",
    "        for word,v in wordcount.items():\n",
    "            #print(word)\n",
    "            if word in self.w2i:\n",
    "                wordcount_filter[self.w2i[word]]=v\n",
    "            else:\n",
    "                wordcount_filter[self.w2i['<UKN>']]+=v\n",
    "        #wordcount_filter[1]=len(trainset) #补充<s>\n",
    "        #wordcount_filter[2]=len(trainset)\n",
    "        \n",
    "        #print(wordcount_filter)\n",
    "                \n",
    "        voc_len = len(self.i2w)\n",
    "        \n",
    "        print(\"计算BiGram概率...\")\n",
    "        self.M = np.zeros((voc_len,voc_len)) #初始化概率矩阵\n",
    "        \n",
    "        #统计二元组合出现次数\n",
    "        print(\"统计二元组出现次数...\")\n",
    "        for sentence in trainset:\n",
    "            sentence_full = ['<S>'] + sentence + ['<E>']\n",
    "            sentence_idx = []\n",
    "            for word in sentence_full:\n",
    "                if word not in self.w2i:\n",
    "                    sentence_idx.append(self.w2i['<UKN>'])\n",
    "                else:\n",
    "                    sentence_idx.append(self.w2i[word])\n",
    "\n",
    "            for i in range(len(sentence_idx)-1):\n",
    "                p1 = sentence_idx[i]\n",
    "                p2 = sentence_idx[i+1]\n",
    "                self.M[p1][p2]+=1\n",
    "        \n",
    "        #计算二元组条件概率\n",
    "        print(\"计算二元组条件概率...\")\n",
    "        for i in range(voc_len):\n",
    "            for j in range(voc_len):\n",
    "                #print(self.M[i][j]+1, wordcount_filter[i], (self.M[i][j]+1)*wordcount_filter[i], (wordcount_filter[i]+wordlist_len))\n",
    "                self.M[i][j]=(1.0*(self.M[i][j]+1)*wordcount_filter[i])/(wordcount_filter[i]+voc_len)\n",
    "                #if self.M[i][j]!=0:\n",
    "                #    print(self.M[i][j])\n",
    "        #print(self.M)\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def perplexity(self, testset):\n",
    "        '''\n",
    "        计算困惑度\n",
    "        '''\n",
    "        sent_perp = [] #存储每句话的困惑度数值\n",
    "        for sentence in testset:\n",
    "            #句子序列添加句首和句尾标签，并将词转换成索引序列\n",
    "            sentence_full = ['<S>'] + sentence + ['<E>']\n",
    "            sentence_idx = []\n",
    "            for word in sentence_full:\n",
    "                if word not in self.w2i:\n",
    "                    sentence_idx.append(self.w2i['<UKN>'])\n",
    "                else:\n",
    "                    sentence_idx.append(self.w2i[word])\n",
    "            #计算每个句子的联合概率\n",
    "            prob = 1\n",
    "            for i in range(len(sentence_idx)-1):\n",
    "                p1 = sentence_idx[i]\n",
    "                p2 = sentence_idx[i+1]\n",
    "                #print(self.M[p1][2])\n",
    "                prob*=1/self.M[p1][2]\n",
    "            \n",
    "            sent_perp.append(np.power(prob,1/len(sentence_full)))#困惑度计算\n",
    "        return np.mean(sent_perp)#返回句子困惑度的均值\n",
    "            \n",
    "    def infer(self):\n",
    "        '''\n",
    "        生成语句\n",
    "        '''\n",
    "        word_sequence = []\n",
    "        #根据句首标签生成下一个位置的词\n",
    "        start_idx = self.w2i['<S>'] \n",
    "        prob_list = self.M[start_idx].tolist()\n",
    "        #print(prob_list[:100])\n",
    "        #选择条件概率最大的前五个候选词，从中随机选择一个，增加多样性\n",
    "        top5_idx = heapq.nlargest(5,range(len(prob_list)),prob_list.__getitem__)\n",
    "        word_idx = top5_idx[random.randint(0,4)]\n",
    "        #print(word_idx,self.i2w[word_idx])\n",
    "        word_sequence.append(self.i2w[word_idx])\n",
    "        start_idx = word_idx\n",
    "        #直到遇到句尾标记停止，否则循环继续\n",
    "        while(word_idx!=self.w2i['<E>']):\n",
    "            prob_list = self.M[start_idx].tolist()\n",
    "            #print(prob_list[:100])\n",
    "            top5_idx = heapq.nlargest(5,range(len(prob_list)),prob_list.__getitem__)\n",
    "            word_idx = top5_idx[random.randint(0,4)]\n",
    "            #print(word_idx,self.i2w[word_idx])\n",
    "            word_sequence.append(self.i2w[word_idx])\n",
    "            start_idx = word_idx\n",
    "        return ' '.join(word_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "705e43ad-36b7-418c-a3a5-12ab36494891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总句子数： 19724\n",
      "词频统计中...\n",
      "生成词表...\n",
      "计算BiGram概率...\n",
      "统计二元组出现次数...\n",
      "计算二元组条件概率...\n",
      "已完成BiGram构建...\n",
      "BiGram困惑度： 32.2570681851328\n",
      "生成的句子： 这就有在新时期的\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "punctions = ['！', '。', '？', ',', '.', '!', '?']  # 添加更多需要的标点符号\n",
    "with open('199801.txt', \"r\", encoding=\"utf-8\") as f:\n",
    "    c = 0\n",
    "    for line in f:\n",
    "        if c > 10000:\n",
    "            break\n",
    "        c += 1\n",
    "        ls = line.strip().split('  ')\n",
    "        line_segs = []\n",
    "        candidate_sentence = []\n",
    "        w_num = 0\n",
    "        for i in range(1, len(ls)):\n",
    "            if ls[i].endswith('/w') and ls[i][0] in punctions:\n",
    "                w_num += 1\n",
    "                if len(candidate_sentence) >= 1:\n",
    "                    sentences.append(candidate_sentence)\n",
    "                    candidate_sentence = []\n",
    "            else:\n",
    "                end_idx = ls[i].index('/')\n",
    "                word = ls[i][:end_idx]\n",
    "                # 检查是否只包含中文字符\n",
    "                if all(u'\\u4e00' <= c <= u'\\u9fff' for c in word):\n",
    "                    candidate_sentence.append(word)\n",
    "        if len(candidate_sentence) > 0:\n",
    "            sentences.append(candidate_sentence)\n",
    "print(\"总句子数：\", len(sentences))\n",
    "\n",
    "# 假设 BiGram 类已经根据需要进行了修改，以支持中文处理和生成\n",
    "split_rate = 0.8\n",
    "topk = 10000\n",
    "\n",
    "bigram = BiGram(topk)\n",
    "\n",
    "split_rate = int(split_rate * len(sentences))\n",
    "bigram.train(sentences[:split_rate])\n",
    "print('已完成BiGram构建...')\n",
    "\n",
    "print('BiGram困惑度：', bigram.perplexity(sentences[split_rate:]))\n",
    "\n",
    "# 生成句子时过滤掉非中文字符\n",
    "sentence = bigram.infer()\n",
    "# 确保只打印中文字符\n",
    "print('生成的句子：', ''.join([c for c in sentence if u'\\u4e00' <= c <= u'\\u9fff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54bb385a-0192-457d-bd2e-8e6256755a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总句子数： 44473\n",
      "词频统计中...\n",
      "生成词表...\n",
      "计算BiGram概率...\n",
      "统计二元组出现次数...\n",
      "计算二元组条件概率...\n",
      "已完成BiGram构建...\n",
      "BiGram困惑度： 13.342639884517247\n",
      "生成的句子: 本报 记者 陈 运鹏 在 新 技术 的 一 种 <UKN> 的 <E>\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "punctions = ['！','。','?','']\n",
    "with open('199801.txt',\"r\",encoding=\"utf-8\") as f:\n",
    "    #c = 0\n",
    "    for line in f:\n",
    "        #if c>10000:\n",
    "        #    break\n",
    "        #c+=1\n",
    "        ls = line.strip().split('  ')\n",
    "        line_segs = []\n",
    "        candidate_sentence = []\n",
    "        w_num = 0\n",
    "        for i in range(1,len(ls)):\n",
    "            if ls[i].endswith('/w') and ls[i][0] in punctions:\n",
    "                w_num+=1\n",
    "                if len(candidate_sentence)>=1:\n",
    "                    sentences.append(candidate_sentence)\n",
    "                    candidate_sentence = []\n",
    "            else:\n",
    "                end_idx = ls[i].index('/')\n",
    "                candidate_sentence.append(ls[i][:end_idx])\n",
    "        if len(candidate_sentence)>0:\n",
    "            sentences.append(candidate_sentence)\n",
    "print(\"总句子数：\",len(sentences))\n",
    "\n",
    "split_rate = 0.8 \n",
    "topk = 10000\n",
    "\n",
    "bigram = BiGram(topk)\n",
    "\n",
    "split_rate = int(split_rate*len(sentences))\n",
    "bigram.train(sentences[:split_rate])\n",
    "print('已完成BiGram构建...')\n",
    "\n",
    "print('BiGram困惑度：',bigram.perplexity(sentences[split_rate:]))\n",
    "\n",
    "#print(bigram.M[0][0])\n",
    "sentence = bigram.infer() \n",
    "print('生成的句子:',sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01281ef6-686c-4abd-80be-9f8686c64b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成的句子: 当着一车乘客的时间你们去干什么\n",
      "困惑度: inf\n"
     ]
    }
   ],
   "source": [
    "#方法二：没有参考BiGram代码，靠个人实现\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# 读取文件内容\n",
    "def read_corpus(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# 清洗和预处理文本\n",
    "def preprocess_text(text):\n",
    "     # 使用正则表达式去除英文字母、标点符号和数字，只保留中文字符和空格\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # 去除标点符号\n",
    "    text = re.sub(r'[a-zA-Z0-9]', '', text)  # 去除英文字母和数字\n",
    "    # 只保留中文字符和空格\n",
    "    text = ''.join(filter(lambda x: x in ' ' or '\\u4e00' <= x <= '\\u9fff', text))\n",
    "    return text.split()\n",
    "\n",
    "# 构建TriGram模型\n",
    "def build_trigram_model(corpus):\n",
    "    if len(corpus) < 3:\n",
    "        raise ValueError(\"Corpus must contain at least three words to build a trigram model.\")\n",
    "    \n",
    "    n_grams = defaultdict(Counter)\n",
    "    bigram_counts = Counter()\n",
    "    \n",
    "    for i in range(len(corpus) - 2):\n",
    "        bigram = (corpus[i], corpus[i + 1])\n",
    "        bigram_counts[bigram] += 1\n",
    "        n_grams[bigram][corpus[i + 2]] += 1\n",
    "    \n",
    "    return n_grams, bigram_counts\n",
    "\n",
    "# 使用模型生成一句话\n",
    "def generate_sentence(trigram_model, bigram_counts, num_words=10):\n",
    "    sentence = []\n",
    "    start_bigram = random.choice(list(bigram_counts.keys()))\n",
    "    sentence.append(start_bigram[0])\n",
    "    sentence.append(start_bigram[1])\n",
    "    \n",
    "    for _ in range(num_words - 2):\n",
    "        if (sentence[-2], sentence[-1]) not in trigram_model:\n",
    "            break\n",
    "        next_word = random.choices(list(trigram_model[(sentence[-2], sentence[-1])].keys()), list(trigram_model[(sentence[-2], sentence[-1])].values()))[0]\n",
    "        sentence.append(next_word)\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "def calculate_perplexity(trigram_model, bigram_counts, corpus):\n",
    "    num_words = len(corpus)\n",
    "    if num_words < 3:\n",
    "        return float('inf')  # 如果少于3个词，困惑度无穷大\n",
    "\n",
    "    joint_probability = 1.0\n",
    "    # 计算开始的bigram的概率\n",
    "    start_bigram_count = bigram_counts.get((corpus[0], corpus[1]), 0)\n",
    "    if start_bigram_count == 0:\n",
    "        return float('inf')  # 如果开始的bigram计数为0，困惑度无穷大\n",
    "    joint_probability *= start_bigram_count\n",
    "    \n",
    "    for i in range(1, num_words - 1):\n",
    "        bigram = (corpus[i - 1], corpus[i])\n",
    "        trigram = (bigram[0], bigram[1], corpus[i + 1])\n",
    "        \n",
    "        bigram_count = bigram_counts[bigram]\n",
    "        trigram_count = trigram_model[bigram].get(trigram[2], 0)\n",
    "        \n",
    "        if bigram_count == 0 or trigram_count == 0:\n",
    "            return float('inf')  # 如果bigram或trigram计数为0，困惑度无穷大\n",
    "        \n",
    "        # 计算条件概率，并更新联合概率\n",
    "        conditional_probability = trigram_count / bigram_count\n",
    "        joint_probability *= conditional_probability\n",
    "    \n",
    "    # 应用困惑度公式\n",
    "    if joint_probability == 0:\n",
    "        return float('inf')  # 如果联合概率为0，困惑度无穷大\n",
    "    perplexity = joint_probability ** (-1.0 / num_words)\n",
    "    return perplexity\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    file_path = 'C:/Users/86184/Desktop/文本分析/199801.txt'\n",
    "    corpus = read_corpus(file_path)\n",
    "    corpus = preprocess_text(corpus)\n",
    "    \n",
    "    if len(corpus) < 3:\n",
    "        raise ValueError(\"Corpus must contain at least three words to build a trigram model.\")\n",
    "        \n",
    "    trigram_model, bigram_counts = build_trigram_model(corpus)\n",
    "    sentence = generate_sentence(trigram_model, bigram_counts, num_words=10)\n",
    "    # 用result代替sentence，并将sentence中的空格删去\n",
    "    result = sentence.replace(\" \", \"\")\n",
    "    print(\"生成的句子:\", result)\n",
    "        \n",
    "    perplexity = calculate_perplexity(trigram_model, bigram_counts, corpus)\n",
    "    print(f\"困惑度: {perplexity}\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ebbb9a-489a-40e4-ad7e-e62a8a234a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#困惑度为无穷大（inf）说明在计算过程中遇到了零概率事件或者模型未能适当地预测数据集中的序列。\n",
    "#说明该模型不够成熟，需要改进，虽然运行速度非常快，但准确性不够。今后还需要继续学习，在实践中总结经验。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
